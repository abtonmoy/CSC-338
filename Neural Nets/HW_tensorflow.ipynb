{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d1a1656",
   "metadata": {},
   "source": [
    "This network uses a hybrid architecture combining several modern techniques:\n",
    "\n",
    "1. Inception Modules - Multi-scale feature extraction through parallel \n",
    "   convolutional paths of different kernel sizes. This allows the network\n",
    "   to capture patterns at multiple scales simultaneously.\n",
    "\n",
    "2. Residual Connections - Skip connections that help gradients flow through\n",
    "   deep networks and allow the network to learn residual mappings.\n",
    "\n",
    "3. Squeeze-and-Excitation Blocks - Channel attention mechanism that learns\n",
    "   to weight feature channels based on their importance for the task.\n",
    "\n",
    "4. Dense Connections - Cross-stage connections that allow features from\n",
    "   earlier layers to directly influence later layers, improving gradient\n",
    "   flow and feature reuse.\n",
    "\n",
    "5. Dual Attention - Combined spatial and channel attention in the final\n",
    "   stages to focus on important regions and features.\n",
    "\n",
    "6. Multi-Scale Pooling - Uses both average and max pooling to capture\n",
    "   different statistical properties of the feature maps.\n",
    "\n",
    "The architecture processes features through three main stages with \n",
    "progressively increasing complexity and abstraction. Early stages use\n",
    "inception modules for multi-scale processing, middle stages use residual\n",
    "learning, and late stages apply attention mechanisms before classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3eea6ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras import layers, models, Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8e76138",
   "metadata": {},
   "source": [
    "In this section you can experiment with whatever ConvNet architecture you'd like on CIFAR-10.\n",
    "\n",
    "You should experiment with architectures, hyperparameters, loss functions, or anything else you can think of to train a model that achieves **at least 70%** accuracy on the **Test** set within 30 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69778197",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load CIFAR-10 dataset\n",
    "(x_train0, y_train0), (x_test0, y_test0) = tf.keras.datasets.cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc76cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Normalize pixel values to [0, 1]\n",
    "x_train = x_train0.reshape(50000, 32, 32, 3).astype(\"float32\") / 255.0\n",
    "x_test = x_test0.reshape(10000, 32, 32, 3).astype(\"float32\") / 255.0\n",
    "y_train = np.asarray(y_train0, dtype=np.int32)\n",
    "y_test = np.asarray(y_test0, dtype=np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc8c99c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inception_block(x, filters):\n",
    "    # Inception module with 4 parallel paths for multi-scale feature extraction\n",
    "    \n",
    "    # Path 1: 1x1 convolution for dimensionality reduction\n",
    "    path1 = layers.Conv2D(filters, (1, 1), padding='same', activation='relu')(x)\n",
    "    \n",
    "    # Path 2: 1x1 reduction followed by 3x3 convolution\n",
    "    path2 = layers.Conv2D(filters, (1, 1), padding='same', activation='relu')(x)\n",
    "    path2 = layers.Conv2D(filters, (3, 3), padding='same', activation='relu')(path2)\n",
    "    \n",
    "    # Path 3: 1x1 reduction followed by two 3x3 convolutions (simulates 5x5)\n",
    "    path3 = layers.Conv2D(filters, (1, 1), padding='same', activation='relu')(x)\n",
    "    path3 = layers.Conv2D(filters, (3, 3), padding='same', activation='relu')(path3)\n",
    "    path3 = layers.Conv2D(filters, (3, 3), padding='same', activation='relu')(path3)\n",
    "    \n",
    "    # Path 4: Max pooling followed by 1x1 convolution\n",
    "    path4 = layers.MaxPooling2D((3, 3), strides=(1, 1), padding='same')(x)\n",
    "    path4 = layers.Conv2D(filters, (1, 1), padding='same', activation='relu')(path4)\n",
    "    \n",
    "    # Concatenate all paths along the channel dimension\n",
    "    return layers.Concatenate()([path1, path2, path3, path4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "614be8ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def residual_block(x, filters):\n",
    "    # Residual block with skip connection for gradient flow\n",
    "    shortcut = x\n",
    "    \n",
    "    # Main path: two conv layers with batch normalization\n",
    "    x = layers.Conv2D(filters, (3, 3), padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    x = layers.Conv2D(filters, (3, 3), padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    \n",
    "    # Adjust shortcut dimensions if needed\n",
    "    if shortcut.shape[-1] != filters:\n",
    "        shortcut = layers.Conv2D(filters, (1, 1), padding='same')(shortcut)\n",
    "        shortcut = layers.BatchNormalization()(shortcut)\n",
    "    \n",
    "    # Add shortcut to main path and apply activation\n",
    "    x = layers.Add()([x, shortcut])\n",
    "    x = layers.Activation('relu')(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d97088",
   "metadata": {},
   "outputs": [],
   "source": [
    "def squeeze_excitation_block(x, ratio=16):\n",
    "    # Channel attention mechanism using squeeze-and-excitation\n",
    "    channels = x.shape[-1]\n",
    "    \n",
    "    # Squeeze: global spatial information into channel descriptor\n",
    "    se = layers.GlobalAveragePooling2D()(x)\n",
    "    \n",
    "    # Excitation: learn channel-wise weights\n",
    "    se = layers.Dense(channels // ratio, activation='relu')(se)\n",
    "    se = layers.Dense(channels, activation='sigmoid')(se)\n",
    "    \n",
    "    # Scale: apply learned weights to input\n",
    "    se = layers.Reshape((1, 1, channels))(se)\n",
    "    return layers.Multiply()([x, se])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c34fa252",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MyNet():\n",
    "    # Build hybrid architecture combining inception, residual, and attention mechanisms\n",
    "    \n",
    "    inputs = layers.Input(shape=(32, 32, 3))\n",
    "    \n",
    "    # Data augmentation applied during training only\n",
    "    x = layers.RandomFlip(\"horizontal\")(inputs)\n",
    "    x = layers.RandomRotation(0.15)(x)\n",
    "    x = layers.RandomZoom(0.1)(x)\n",
    "    x = layers.RandomContrast(0.2)(x)\n",
    "    \n",
    "    # Initial feature extraction\n",
    "    x = layers.Conv2D(32, (3, 3), padding='same', activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    \n",
    "    # Stage 1: Multi-scale feature extraction at 32x32 resolution\n",
    "    inception1 = inception_block(x, 16)\n",
    "    inception1 = layers.BatchNormalization()(inception1)\n",
    "    inception1 = layers.Dropout(0.2)(inception1)\n",
    "    \n",
    "    residual1 = residual_block(inception1, 64)\n",
    "    se1 = squeeze_excitation_block(residual1)\n",
    "    \n",
    "    # Reduce spatial dimensions to 16x16\n",
    "    x = layers.MaxPooling2D((2, 2))(se1)\n",
    "    \n",
    "    # Stage 2: Deeper feature learning at 16x16 resolution\n",
    "    inception2 = inception_block(x, 24)\n",
    "    inception2 = layers.BatchNormalization()(inception2)\n",
    "    inception2 = layers.Dropout(0.3)(inception2)\n",
    "    \n",
    "    residual2 = residual_block(inception2, 96)\n",
    "    se2 = squeeze_excitation_block(residual2)\n",
    "    \n",
    "    # Dense connection: add features from stage 1 to stage 2\n",
    "    se1_pooled = layers.MaxPooling2D((2, 2))(se1)\n",
    "    se1_adjusted = layers.Conv2D(96, (1, 1), padding='same')(se1_pooled)\n",
    "    dense_concat1 = layers.Add()([se2, se1_adjusted])\n",
    "    \n",
    "    # Reduce spatial dimensions to 8x8\n",
    "    x = layers.MaxPooling2D((2, 2))(dense_concat1)\n",
    "    \n",
    "    # Stage 3: Deep feature processing at 8x8 resolution\n",
    "    residual3a = residual_block(x, 128)\n",
    "    residual3a = layers.Dropout(0.35)(residual3a)\n",
    "    \n",
    "    residual3b = residual_block(residual3a, 128)\n",
    "    se3 = squeeze_excitation_block(residual3b)\n",
    "    \n",
    "    # Dual attention mechanism for comprehensive feature refinement\n",
    "    # Path A: spatial attention to focus on important regions\n",
    "    spatial_attention = layers.Conv2D(1, (7, 7), padding='same', activation='sigmoid')(se3)\n",
    "    spatial_features = layers.Multiply()([se3, spatial_attention])\n",
    "    \n",
    "    # Path B: additional channel-wise transformation\n",
    "    channel_features = layers.Conv2D(128, (1, 1), activation='relu')(se3)\n",
    "    \n",
    "    # Combine both attention paths\n",
    "    x = layers.Concatenate()([spatial_features, channel_features])\n",
    "    x = layers.Conv2D(256, (1, 1), activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dropout(0.4)(x)\n",
    "    \n",
    "    # Final feature compression\n",
    "    x = layers.Conv2D(192, (3, 3), padding='same', activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    \n",
    "    # Multi-scale global pooling to capture both average and max activations\n",
    "    gap = layers.GlobalAveragePooling2D()(x)\n",
    "    gmp = layers.GlobalMaxPooling2D()(x)\n",
    "    x = layers.Concatenate()([gap, gmp])\n",
    "    \n",
    "    # Classification head\n",
    "    x = layers.Dense(384, activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    \n",
    "    x = layers.Dense(192, activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dropout(0.4)(x)\n",
    "    \n",
    "    outputs = layers.Dense(10, activation='softmax')(x)\n",
    "    \n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    \n",
    "    # Compile model with Adam optimizer\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a16072c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and display model\n",
    "model = MyNet()\n",
    "model.summary()\n",
    "print(f\"\\nTotal parameters: {model.count_params():,}\")\n",
    "\n",
    "# Setup training callbacks\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor='val_accuracy', patience=7, restore_best_weights=True),\n",
    "    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=4, min_lr=1e-7, verbose=1)\n",
    "]\n",
    "\n",
    "# Train the model\n",
    "print(\"\\nStarting training...\")\n",
    "training_history = model.fit(\n",
    "    x_train, y_train,\n",
    "    epochs=30,\n",
    "    batch_size=64,\n",
    "    validation_split=0.2,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa734a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training curves\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"TRAINING HISTORY\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "epochs_range = range(1, len(training_history.history['accuracy']) + 1)\n",
    "\n",
    "# Accuracy plot\n",
    "ax1.plot(epochs_range, training_history.history['accuracy'], \n",
    "         label='Training', linewidth=2, marker='o', markersize=3)\n",
    "ax1.plot(epochs_range, training_history.history['val_accuracy'], \n",
    "         label='Validation', linewidth=2, marker='s', markersize=3)\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('Accuracy')\n",
    "ax1.set_title('Model Accuracy')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Loss plot\n",
    "ax2.plot(epochs_range, training_history.history['loss'], \n",
    "         label='Training', linewidth=2, marker='o', markersize=3)\n",
    "ax2.plot(epochs_range, training_history.history['val_loss'], \n",
    "         label='Validation', linewidth=2, marker='s', markersize=3)\n",
    "ax2.set_xlabel('Epoch')\n",
    "ax2.set_ylabel('Loss')\n",
    "ax2.set_title('Model Loss')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('training_history.png', dpi=150)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Evaluate on test set\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"TEST SET PERFORMANCE\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "test_loss, test_accuracy = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(f\"\\nTest Loss: {test_loss:.4f}\")\n",
    "print(f\"Test Accuracy: {test_accuracy*100:.2f}%\")\n",
    "\n",
    "if test_accuracy >= 0.70:\n",
    "    print(f\"Target achieved (>= 70%)\")\n",
    "else:\n",
    "    print(f\"Target not met - need {(0.70 - test_accuracy)*100:.2f}% more\")\n",
    "\n",
    "\n",
    "# Save model architecture diagram\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"SAVING NETWORK DIAGRAM\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "try:\n",
    "    plot_model(model, to_file='model_architecture.png', \n",
    "               show_shapes=True, show_layer_names=True, \n",
    "               rankdir='TB', dpi=150)\n",
    "    print(\"Network diagram saved to 'model_architecture.png'\")\n",
    "except Exception as e:\n",
    "    print(f\"Could not save diagram: {e}\")\n",
    "    print(\"Install graphviz and pydot if needed\")\n",
    "\n",
    "\n",
    "# Sample predictions\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"SAMPLE PREDICTIONS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer', \n",
    "               'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "\n",
    "fig, axes = plt.subplots(2, 5, figsize=(15, 6))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for i in range(10):\n",
    "    idx = np.random.randint(0, len(x_test))\n",
    "    prediction = model.predict(x_test[idx:idx+1], verbose=0)\n",
    "    pred_label = np.argmax(prediction)\n",
    "    confidence = np.max(prediction) * 100\n",
    "    true_label = y_test[idx][0]\n",
    "    \n",
    "    axes[i].imshow(x_test0[idx])\n",
    "    axes[i].axis('off')\n",
    "    \n",
    "    # Color code correct vs incorrect predictions\n",
    "    color = 'green' if pred_label == true_label else 'red'\n",
    "    axes[i].set_title(f'True: {class_names[true_label]}\\nPred: {class_names[pred_label]} ({confidence:.1f}%)',\n",
    "                     color=color, fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('sample_predictions.png', dpi=150)\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nTraining complete.\")\n",
    "print(f\"Final test accuracy: {test_accuracy*100:.2f}%\")\n",
    "print(f\"Total parameters: {model.count_params():,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b00dff08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i, img in enumerate(x_test0[0:64]):\n",
    "#     plt.subplot(8, 8, i+1)\n",
    "#     plt.imshow(img, cmap='gray')\n",
    "#     plt.axis('off')\n",
    "#     #prediction = model.predict(x_test[i:i+1])\n",
    "#     #pred_label = np.argmax(prediction)\n",
    "    \n",
    "   \n",
    "#     plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "146283de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def MyNet():\n",
    "#     # your code here\n",
    "#     model = tf.keras.Sequential([\n",
    "       \n",
    "#     ])\n",
    "#     # you can modify the optimizer as needed\n",
    "#     model.compile(optimizer='adam',\n",
    "#               loss='sparse_categorical_crossentropy',\n",
    "#               metrics=['accuracy'])\n",
    "#     return model\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b37f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = MyNet()\n",
    "# training_history = model.fit(x_train, y_train, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12cf8621",
   "metadata": {},
   "source": [
    "In the cell below:  \n",
    "\n",
    "1) Plot the network diagram\n",
    "2) Write an explanation of what you did\n",
    "3) Plot the loss and accuracy graph over epoches\n",
    "4) Report accuracy on Test dataset. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.13.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
